# ArXiv Academic Paper Crawler

ä¸€ä¸ªåŠŸèƒ½å®Œå–„çš„ ArXiv å­¦æœ¯è®ºæ–‡çˆ¬è™«ç³»ç»Ÿï¼Œæ”¯æŒè®ºæ–‡æœç´¢ã€ä¸‹è½½ã€ç®¡ç†å’Œæ•°æ®åˆ†æã€‚

## åŠŸèƒ½ç‰¹æ€§

### ğŸ” å¼ºå¤§çš„æœç´¢åŠŸèƒ½
- æ”¯æŒå…³é”®è¯ã€ä½œè€…ã€æ ‡é¢˜ã€æ‘˜è¦æœç´¢
- æŒ‰å­¦ç§‘åˆ†ç±»æœç´¢ï¼ˆå¦‚ cs.AI, physics.gen-ph ç­‰ï¼‰
- æ—¶é—´èŒƒå›´ç­›é€‰
- é«˜çº§æŸ¥è¯¢è¯­æ³•æ”¯æŒï¼ˆAND, OR, NOTï¼‰
- åˆ†é¡µæŸ¥è¯¢ï¼Œæ”¯æŒå¤§é‡ç»“æœå¤„ç†

### ğŸ“¥ æ™ºèƒ½ä¸‹è½½ç®¡ç†
- å¤šçº¿ç¨‹å¹¶å‘ä¸‹è½½ï¼Œå¯é…ç½®çº¿ç¨‹æ•°
- æ–­ç‚¹ç»­ä¼ æ”¯æŒ
- è¿›åº¦æ¡æ˜¾ç¤ºï¼ˆæ•´ä½“å’Œå•æ–‡ä»¶è¿›åº¦ï¼‰
- å¤±è´¥è‡ªåŠ¨é‡è¯•æœºåˆ¶
- äº¤äº’å¼é€‰æ‹©ä¸‹è½½
- æ™ºèƒ½æ–‡ä»¶å‘½åå’Œåˆ†ç±»å­˜å‚¨

### ğŸ’¾ æ•°æ®å­˜å‚¨ä¸ç®¡ç†
- SQLite æ•°æ®åº“å­˜å‚¨è®ºæ–‡å…ƒæ•°æ®
- JSON/CSV æ ¼å¼å¯¼å‡º
- æ•°æ®å»é‡æœºåˆ¶
- å¢é‡æ›´æ–°åŠŸèƒ½
- æœ¬åœ°æœç´¢æ”¯æŒ
- ç»Ÿè®¡ä¿¡æ¯åˆ†æ

### ğŸ–¥ï¸ ç”¨æˆ·ç•Œé¢
- ä¸°å¯Œçš„å‘½ä»¤è¡Œç•Œé¢ï¼ˆä½¿ç”¨ Rich åº“ç¾åŒ–ï¼‰
- äº¤äº’å¼èœå•æ¨¡å¼
- è¯¦ç»†çš„å¸®åŠ©ä¿¡æ¯
- é…ç½®æ–‡ä»¶ç®¡ç†

## å®‰è£…è¦æ±‚

### ç³»ç»Ÿè¦æ±‚
- Python 3.7 æˆ–æ›´é«˜ç‰ˆæœ¬
- Windows 10+, macOS 10.14+, æˆ– Linux

### ä¾èµ–åº“
```bash
pip install -r requirements.txt
```

ä¸»è¦ä¾èµ–ï¼š
- `requests` - HTTP è¯·æ±‚
- `feedparser` - ArXiv API å“åº”è§£æ
- `pandas` - æ•°æ®å¤„ç†
- `tqdm` - è¿›åº¦æ¡
- `rich` - ç»ˆç«¯ç¾åŒ–
- `click` - å‘½ä»¤è¡Œç•Œé¢
- `pyyaml` - é…ç½®æ–‡ä»¶å¤„ç†

## å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–
```bash
# å…‹éš†æˆ–ä¸‹è½½é¡¹ç›®
# å®‰è£…ä¾èµ–
pip install -r requirements.txt
```

### 2. åŸºæœ¬ä½¿ç”¨

#### æœç´¢è®ºæ–‡
```bash
# å…³é”®è¯æœç´¢
python main.py search --query "machine learning" --max-results 10

# ä½œè€…æœç´¢
python main.py search --author "Yann LeCun" --category "cs.AI"

# åˆ†ç±»æœç´¢
python main.py search --category "cs.CV" --date-from "2023-01-01"

# é«˜çº§æœç´¢
python main.py search --title "neural networks" --abstract "deep learning" --max-results 50
```

#### ä¸‹è½½è®ºæ–‡
```bash
# æœç´¢å¹¶ä¸‹è½½
python main.py download --query "deep learning" --max-results 20 --interactive

# ä» JSON æ–‡ä»¶ä¸‹è½½
python main.py download --input results.json --threads 8

# æŒ‡å®šè¾“å‡ºç›®å½•
python main.py download --query "computer vision" --output-dir ./cv_papers
```

#### æ•°æ®åº“ç®¡ç†
```bash
# æŸ¥çœ‹ç»Ÿè®¡ä¿¡æ¯
python main.py stats

# æœç´¢æœ¬åœ°æ•°æ®åº“
python main.py search-local --query "transformer" --fields "title,abstract"

# æ›´æ–°æ•°æ®åº“ï¼ˆè·å–æœ€è¿‘ 7 å¤©çš„è®ºæ–‡ï¼‰
python main.py update --category "cs.AI" --days 7

# æ•°æ®åº“æ¸…ç†
python main.py cleanup --backup
```

#### å…¶ä»–åŠŸèƒ½
```bash
# æŸ¥çœ‹å¯ç”¨åˆ†ç±»
python main.py categories

# äº¤äº’å¼æ¨¡å¼
python main.py --interactive

# æŸ¥çœ‹å¸®åŠ©
python main.py --help
python main.py COMMAND --help
```

## é…ç½®æ–‡ä»¶

é…ç½®æ–‡ä»¶ `config.yaml` åŒ…å«æ‰€æœ‰å¯é…ç½®é€‰é¡¹ï¼š

```yaml
api:
  base_url: "http://export.arxiv.org/api/query"
  max_results_per_query: 100
  request_delay: 3.0
  user_agent: "ArxivCrawler/1.0"
  timeout: 30

download:
  output_directory: "./downloaded_papers"
  max_concurrent_downloads: 5
  retry_attempts: 3
  timeout: 60
  filename_pattern: "{year}_{first_author}_{title}"
  create_category_folders: true

storage:
  database_path: "./arxiv_papers.db"
  export_formats: ["json", "csv"]
  auto_backup: true

logging:
  level: "INFO"
  log_file: "arxiv_crawler.log"
  max_file_size: "10MB"
  backup_count: 3
```

## ç¯å¢ƒå˜é‡

å¯ä»¥ä½¿ç”¨ç¯å¢ƒå˜é‡è¦†ç›–é…ç½®æ–‡ä»¶è®¾ç½®ï¼š

```bash
export ARXIV_DOWNLOAD_DIR="/path/to/papers"
export ARXIV_DOWNLOAD_THREADS=10
export ARXIV_API_DELAY=5
export ARXIV_LOG_LEVEL=DEBUG
```

## é«˜çº§åŠŸèƒ½

### æ–‡ä»¶å‘½åæ¨¡å¼
æ”¯æŒè‡ªå®šä¹‰æ–‡ä»¶å‘½åï¼Œå¯ç”¨å˜é‡ï¼š
- `{year}` - å‘è¡¨å¹´ä»½
- `{first_author}` - ç¬¬ä¸€ä½œè€…
- `{title}` - è®ºæ–‡æ ‡é¢˜
- `{arxiv_id}` - ArXiv ID

### æ•°æ®å¯¼å‡º
```bash
# å¯¼å‡ºæœç´¢ç»“æœ
python main.py search --query "quantum computing" --export results.json
python main.py search --query "quantum computing" --export results.csv

# å¯¼å‡ºç»Ÿè®¡ä¿¡æ¯
python main.py stats --export statistics.json
```

### æ‰¹é‡æ“ä½œ
```python
# ä½¿ç”¨ Python API
from arxiv_api import ArxivAPI
from data_processor import DataProcessor
from downloader import DownloadManager

# åˆå§‹åŒ–
api = ArxivAPI(config)
processor = DataProcessor(config)
downloader = DownloadManager(config)

# æœç´¢
results = api.search(query="machine learning", max_results=100)

# å¤„ç†æ•°æ®
processor.add_papers(results['papers'])

# ä¸‹è½½
download_results = downloader.download_papers(results['papers'])
```

## å¸¸è§é—®é¢˜

### Q: ä¸‹è½½å¤±è´¥æ€ä¹ˆåŠï¼Ÿ
A: ç³»ç»Ÿæä¾›è‡ªåŠ¨é‡è¯•æœºåˆ¶ã€‚ä½ ä¹Ÿå¯ä»¥ä½¿ç”¨ `--retry` é€‰é¡¹æ‰‹åŠ¨é‡è¯•å¤±è´¥çš„ä¸‹è½½ã€‚

### Q: å¦‚ä½•é¿å…è¢« ArXiv å°ç¦ï¼Ÿ
A: é»˜è®¤é…ç½®éµå®ˆ ArXiv API ä½¿ç”¨è§„èŒƒï¼ˆ3ç§’è¯·æ±‚é—´éš”ï¼‰ã€‚è¯·å‹¿ä¿®æ”¹ `request_delay` ä¸ºå°äº 3 ç§’çš„å€¼ã€‚

### Q: æ”¯æŒå“ªäº›è®ºæ–‡åˆ†ç±»ï¼Ÿ
A: ä½¿ç”¨ `python main.py categories` æŸ¥çœ‹æ‰€æœ‰å¯ç”¨çš„ ArXiv åˆ†ç±»ã€‚

### Q: å¦‚ä½•å¤„ç†ç½‘ç»œä»£ç†ï¼Ÿ
A: å¯ä»¥è®¾ç½®ç¯å¢ƒå˜é‡ï¼š
```bash
export HTTP_PROXY=http://proxy:8080
export HTTPS_PROXY=http://proxy:8080
```

### Q: æ•°æ®åº“æ–‡ä»¶åœ¨å“ªé‡Œï¼Ÿ
A: é»˜è®¤åœ¨å½“å‰ç›®å½•çš„ `arxiv_papers.db`ï¼Œå¯åœ¨é…ç½®æ–‡ä»¶ä¸­ä¿®æ”¹ã€‚

## é¡¹ç›®ç»“æ„

```
paper_spider/
â”œâ”€â”€ main.py              # ä¸»ç¨‹åºå…¥å£
â”œâ”€â”€ cli.py               # å‘½ä»¤è¡Œæ¥å£
â”œâ”€â”€ arxiv_api.py         # ArXiv API å°è£…
â”œâ”€â”€ data_processor.py    # æ•°æ®å¤„ç†æ¨¡å—
â”œâ”€â”€ downloader.py        # ä¸‹è½½ç®¡ç†å™¨
â”œâ”€â”€ config.py            # é…ç½®ç®¡ç†
â”œâ”€â”€ requirements.txt     # ä¾èµ–åˆ—è¡¨
â”œâ”€â”€ config.yaml          # é…ç½®æ–‡ä»¶
â”œâ”€â”€ setup.py            # å®‰è£…è„šæœ¬
â””â”€â”€ README.md           # è¯´æ˜æ–‡æ¡£
```

## å¼€å‘è¯´æ˜

### è¿è¡Œæµ‹è¯•
```bash
python -m pytest tests/
```

### ä»£ç æ ¼å¼åŒ–
```bash
black *.py
flake8 *.py
```

### æ„å»ºåˆ†å‘åŒ…
```bash
python setup.py sdist bdist_wheel
```

## è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ - è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶ã€‚

## è´¡çŒ®

æ¬¢è¿è´¡çŒ®ä»£ç ï¼è¯·ï¼š

1. Fork æœ¬é¡¹ç›®
2. åˆ›å»ºåŠŸèƒ½åˆ†æ”¯ (`git checkout -b feature/AmazingFeature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add some AmazingFeature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/AmazingFeature`)
5. å¼€å¯ Pull Request

## è”ç³»æ–¹å¼

- é¡¹ç›®ä¸»é¡µï¼šhttps://github.com/Nathanielneil/paper_spider
- é—®é¢˜åé¦ˆï¼šhttps://github.com/Nathanielneil/paper_spider/issues

## æ›´æ–°æ—¥å¿—

### v1.0.0 (2025-09-11)
- åˆå§‹ç‰ˆæœ¬å‘å¸ƒ
- å®Œæ•´çš„æœç´¢å’Œä¸‹è½½åŠŸèƒ½
- æ•°æ®åº“å­˜å‚¨å’Œç®¡ç†
- ä¸°å¯Œçš„å‘½ä»¤è¡Œç•Œé¢
- è·¨å¹³å°æ”¯æŒï¼ˆWindows/macOS/Linuxï¼‰

---

**æ³¨æ„ï¼šæœ¬å·¥å…·ä»…ä¾›å­¦æœ¯ç ”ç©¶ä½¿ç”¨ï¼Œè¯·éµå®ˆ ArXiv çš„ä½¿ç”¨æ¡æ¬¾å’Œç‰ˆæƒå£°æ˜ã€‚**
